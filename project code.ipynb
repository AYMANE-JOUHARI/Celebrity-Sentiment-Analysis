{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3f27e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Title: Sentiment Analysis of Social Media Comments\n",
    "# Description: This notebook preprocesses data, trains various models for sentiment analysis, and evaluates their performance.\n",
    "\n",
    "# Step 1: Import Necessary Libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import seaborn as sns\n",
    "\n",
    "# Download NLTK data (run only once)\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b141ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Load and Explore Dataset\n",
    "# Load data and display basic information\n",
    "df = pd.read_csv('SaadLamjarred_LV.csv')\n",
    "df = df[['Comments', 'Label']].dropna()  # Keep only relevant columns and remove null values\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(\"First few rows of the dataset:\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8674e173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Data Preprocessing\n",
    "# Preprocessing function to clean text data\n",
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    Preprocess text by removing special characters, converting to lowercase, \n",
    "    removing stopwords, and applying stemming.\n",
    "    \"\"\"\n",
    "    text = re.sub(r'[^\\w\\s]', '', text.lower())  # Remove special characters and lowercase\n",
    "    stop_words = set(stopwords.words('arabic'))  # Adjust stop words based on language\n",
    "    stemmer = PorterStemmer()\n",
    "    tokens = [stemmer.stem(word) for word in text.split() if word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply preprocessing to the 'Comments' column\n",
    "df['processed_comments'] = df['Comments'].apply(preprocess_text)\n",
    "print(\"Sample processed comments:\")\n",
    "print(df['processed_comments'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a64c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Split Data into Training, Validation, and Test Sets\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d308679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Model Training and Evaluation\n",
    "# Train and evaluate multiple models\n",
    "\n",
    "# Logistic Regression\n",
    "lr = LogisticRegression(random_state=42)\n",
    "lr.fit(X_train, y_train)\n",
    "print(\"Logistic Regression\")\n",
    "print(\"Training accuracy:\", lr.score(X_train, y_train))\n",
    "print(\"Validation accuracy:\", lr.score(X_val, y_val))\n",
    "print(\"Test accuracy:\", lr.score(X_test, y_test))\n",
    "print()\n",
    "\n",
    "# Naive Bayes\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "print(\"Naive Bayes\")\n",
    "print(\"Training accuracy:\", nb.score(X_train, y_train))\n",
    "print(\"Validation accuracy:\", nb.score(X_val, y_val))\n",
    "print(\"Test accuracy:\", nb.score(X_test, y_test))\n",
    "print()\n",
    "\n",
    "# Linear Discriminant Analysis (LDA)\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(X_train.toarray(), y_train)\n",
    "print(\"LDA\")\n",
    "print(\"Training accuracy:\", lda.score(X_train.toarray(), y_train))\n",
    "print(\"Validation accuracy:\", lda.score(X_val.toarray(), y_val))\n",
    "print(\"Test accuracy:\", lda.score(X_test.toarray(), y_test))\n",
    "print()\n",
    "\n",
    "# Quadratic Discriminant Analysis (QDA)\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "qda.fit(X_train.toarray(), y_train)\n",
    "print(\"QDA\")\n",
    "print(\"Training accuracy:\", qda.score(X_train.toarray(), y_train))\n",
    "print(\"Validation accuracy:\", qda.score(X_val.toarray(), y_val))\n",
    "print(\"Test accuracy:\", qda.score(X_test.toarray(), y_test))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ec58b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 7: Logistic Regression with Grid Search for Hyperparameter Tuning\n",
    "param_grid = {'C': [0.1, 1, 10], 'penalty': ['l2']}\n",
    "grid_search = GridSearchCV(LogisticRegression(random_state=42), param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Logistic Regression with Grid Search\")\n",
    "print(\"Training accuracy:\", grid_search.score(X_train, y_train))\n",
    "print(\"Validation accuracy:\", grid_search.score(X_val, y_val))\n",
    "print(\"Test accuracy:\", grid_search.score(X_test, y_test))\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca4f7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Model Performance Visualization with Confusion Matrix (for best model)\n",
    "y_pred = lr.predict(X_test)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix - Logistic Regression\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5246d161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Prediction on New Comments\n",
    "# Predicting sentiments for new comments\n",
    "new_comments = [\"فنان يتغنى في كل مرة بترات المغرب تحياتي\"]\n",
    "new_comments_tfidf = tfidf.transform(new_comments)\n",
    "predicted_sentiments = lr.predict(new_comments_tfidf)\n",
    "\n",
    "# Mapping predictions to sentiment labels\n",
    "label_mapping = {-1: \"Negative\", 1: \"Positive\"}\n",
    "predicted_labels = [label_mapping[sentiment] for sentiment in predicted_sentiments]\n",
    "\n",
    "# Display results\n",
    "for comment, label in zip(new_comments, predicted_labels):\n",
    "    print(f\"Comment: {comment}\\nPredicted Sentiment: {label}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03aaf53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10: Save Labeled Comments to CSV\n",
    "# (Optional) Save new comments with predicted sentiments\n",
    "comments_df = pd.DataFrame({'Comments': new_comments, 'Sentiment': predicted_labels})\n",
    "comments_df.to_csv('labeled_comments.csv', index=False)\n",
    "print(\"New labeled comments saved to 'labeled_comments.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
